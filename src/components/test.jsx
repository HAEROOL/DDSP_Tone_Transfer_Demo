import React, { useState } from "react";
import * as mm from "@magenta/music";

// WAV ì¸ì½”ë”© í—¬í¼ í•¨ìˆ˜ë“¤
function writeString(view, offset, str) {
  for (let i = 0; i < str.length; i++) {
    view.setUint8(offset + i, str.charCodeAt(i));
  }
}
function floatTo16BitPCM(output, offset, input) {
  for (let i = 0; i < input.length; i++, offset += 2) {
    let s = Math.max(-1, Math.min(1, input[i]));
    output.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7fff, true);
  }
}
function encodeWAV(samples, sampleRate) {
  const buffer = new ArrayBuffer(44 + samples.length * 2);
  const view = new DataView(buffer);
  const channels = 1;
  writeString(view, 0, "RIFF");
  view.setUint32(4, 36 + samples.length * 2, true);
  writeString(view, 8, "WAVE");
  writeString(view, 12, "fmt ");
  view.setUint32(16, 16, true);
  view.setUint16(20, 1, true);
  view.setUint16(22, channels, true);
  view.setUint32(24, sampleRate, true);
  view.setUint32(28, sampleRate * channels * 2, true);
  view.setUint16(32, channels * 2, true);
  view.setUint16(34, 16, true);
  writeString(view, 36, "data");
  view.setUint32(40, samples.length * 2, true);
  floatTo16BitPCM(view, 44, samples);
  return view;
}

// ë‹¤ìš´ë¯¹ìŠ¤ + ë¦¬ìƒ˜í”Œë§ (ìŠ¤í…Œë ˆì˜¤ â†’ ëª¨ë…¸, 16kHz, targetLength ë³´ì¥)
async function downmixAndResample(inputBuffer, targetSampleRate, targetLength) {
  const durationSec = inputBuffer.duration;
  const targetSamples =
    targetLength || Math.ceil(durationSec * targetSampleRate);
  const offlineCtx = new OfflineAudioContext(
    1,
    targetSamples,
    targetSampleRate
  );
  const source = offlineCtx.createBufferSource();
  source.buffer = inputBuffer;
  source.connect(offlineCtx.destination);
  source.start();
  const resampledBuffer = await offlineCtx.startRendering();
  console.log("âœ… Resampled AudioBuffer length:", resampledBuffer.length);
  return resampledBuffer;
}

/**
 * ì£¼ì–´ì§„ AudioBufferë¥¼ targetLength(ìƒ˜í”Œ ìˆ˜)ë¡œ ìë¥´ê±°ë‚˜,
 * ë¶€ì¡±í•œ ê²½ìš° 0ìœ¼ë¡œ íŒ¨ë”©í•˜ì—¬ ê³ ì • ê¸¸ì´(ì•½ 20480 ìƒ˜í”Œ)ë¡œ ë§Œë“­ë‹ˆë‹¤.
 */
function cropOrPadAudioBuffer(buffer, targetLength) {
  const numChannels = buffer.numberOfChannels;
  const sampleRate = buffer.sampleRate;
  const ctx = new AudioContext();
  const newBuffer = ctx.createBuffer(numChannels, targetLength, sampleRate);
  for (let ch = 0; ch < numChannels; ch++) {
    const oldData = buffer.getChannelData(ch);
    const newData = newBuffer.getChannelData(ch);
    const copyLength = Math.min(oldData.length, targetLength);
    newData.set(oldData.subarray(0, copyLength));
    if (oldData.length < targetLength) {
      for (let i = oldData.length; i < targetLength; i++) {
        newData[i] = 0;
      }
    }
  }
  ctx.close();
  console.log("âœ… Fixed AudioBuffer length:", newBuffer.length);
  return newBuffer;
}

const MODEL = {
  VIOLIN: "violin",
  TENOR_SAXOPHONE: "tenor_saxophone",
  TRUMPET: "trumpet",
  FLUTE: "flute",
};

const PRESET_MODEL_URL =
  "https://storage.googleapis.com/magentadata/js/checkpoints/ddsp";

const Test = () => {
  const [initialized, setInitialized] = useState(false);
  const [spice, setSpice] = useState(null);
  const [audioCtx, setAudioCtx] = useState(null);
  const [audioFeatures, setAudioFeatures] = useState(null);
  const [uploadedAudioUrl, setUploadedAudioUrl] = useState(null);
  const [convertedUrl, setConvertedUrl] = useState(null);
  const [errorMsg, setErrorMsg] = useState("");

  // ì´ˆê¸°í™” ë²„íŠ¼ í´ë¦­ ì‹œ SPICE ëª¨ë¸ê³¼ AudioContext ìƒì„±
  const handleInitialize = async () => {
    try {
      const spiceModel = new mm.SPICE("/spice"); // ë¡œì»¬ ê²½ë¡œ "/spice"
      await spiceModel.initialize();
      setSpice(spiceModel);
      const ctx = new AudioContext();
      setAudioCtx(ctx);
      setInitialized(true);
    } catch (error) {
      console.error("ì´ˆê¸°í™” ì˜¤ë¥˜:", error);
      setErrorMsg(error.message);
    }
  };

  // íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬
  const handleFileChange = async (e) => {
    if (e.target.files && e.target.files.length > 0) {
      const file = e.target.files[0];
      // ìƒì„±ëœ Blob URLë¡œ ì—…ë¡œë“œëœ íŒŒì¼ ì¬ìƒìš© URL ì„¤ì •
      const url = URL.createObjectURL(file);
      setUploadedAudioUrl(url);

      try {
        // íŒŒì¼ì„ ArrayBufferë¡œ ì½ìŒ
        const arrayBuffer = await file.arrayBuffer();
        const decodedBuffer = await audioCtx.decodeAudioData(arrayBuffer);
        console.log("ğŸ” Original AudioBuffer Length:", decodedBuffer.length);
        console.log(
          "ğŸ” Original Audio Data (first 10 samples):",
          decodedBuffer.getChannelData(0).slice(0, 10)
        );

        // SPICE ëª¨ë¸ì— ì „ë‹¬í•  ìˆ˜ ìˆë„ë¡ ë‹¤ìš´ë¯¹ìŠ¤/ë¦¬ìƒ˜í”Œë§ ë° ê³ ì • ê¸¸ì´ ì²˜ë¦¬
        const resampledBuffer = await downmixAndResample(
          decodedBuffer,
          16000,
          20480
        );
        console.log("âœ… Resampled AudioBuffer:", resampledBuffer);
        const fixedBuffer = cropOrPadAudioBuffer(resampledBuffer, 20480);
        console.log("ğŸ¯ Final Fixed Buffer:", fixedBuffer);
        setAudioFeatures(await spice.getAudioFeatures(fixedBuffer));
        console.log("âœ… SPICE audioFeatures set.");
      } catch (error) {
        console.error("íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜:", error);
        setErrorMsg(error.message);
      }
    }
  };

  // í†¤ íŠ¸ëœìŠ¤í¼ í•¨ìˆ˜ (ê° ì•…ê¸° ë²„íŠ¼ì—ì„œ í˜¸ì¶œ)
  const toneTransfer = async (checkpointUrl, settings) => {
    try {
      setConvertedUrl(null);
      const ddsp = new mm.DDSP(checkpointUrl, settings);
      await ddsp.initialize();
      const toneTransferredAudioData = await ddsp.synthesize(audioFeatures);
      const dataview = encodeWAV(toneTransferredAudioData, audioCtx.sampleRate);
      const wavBlob = new Blob([dataview], { type: "audio/wav" });
      const url = URL.createObjectURL(wavBlob);
      setConvertedUrl(url);
      ddsp.dispose();
    } catch (error) {
      console.error("í†¤ íŠ¸ëœìŠ¤í¼ ì˜¤ë¥˜:", error);
      setErrorMsg(error.message);
    }
  };

  return (
    <div style={{ padding: "1rem" }}>
      <h1>Magenta.js ê¸°ë°˜ ìŒì„± ë³€í™˜ ë°ëª¨</h1>
      {errorMsg && <p style={{ color: "red" }}>Error: {errorMsg}</p>}
      {!initialized ? (
        <button onClick={handleInitialize}>Initialize SPICE Model</button>
      ) : (
        <>
          <p>SPICE ëª¨ë¸ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.</p>
          <div>
            <input type="file" accept="audio/*" onChange={handleFileChange} />
            {uploadedAudioUrl && (
              <div>
                <h3>ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤</h3>
                <audio src={uploadedAudioUrl} controls />
              </div>
            )}
          </div>
          {audioFeatures && (
            <div>
              <h3>Tone Transfer</h3>
              <button
                onClick={() =>
                  toneTransfer(`${PRESET_MODEL_URL}/${MODEL.VIOLIN}`)
                }
              >
                Violin
              </button>
              <button
                onClick={() =>
                  toneTransfer(`${PRESET_MODEL_URL}/${MODEL.TENOR_SAXOPHONE}`)
                }
              >
                Tenor Saxophone
              </button>
              <button
                onClick={() =>
                  toneTransfer(`${PRESET_MODEL_URL}/${MODEL.FLUTE}`)
                }
              >
                Flute
              </button>
              <button
                onClick={() =>
                  toneTransfer(`${PRESET_MODEL_URL}/${MODEL.TRUMPET}`)
                }
              >
                Trumpet
              </button>
            </div>
          )}
          {convertedUrl && (
            <div>
              <h3>ë³€í™˜ëœ ìŒì›</h3>
              <audio src={convertedUrl} controls />
            </div>
          )}
        </>
      )}
    </div>
  );
};

export default Test;
